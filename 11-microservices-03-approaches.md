# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Решение 1

Современные популярные инструменты CI/CD для процесса разработки обеспечивают требования, предъявляемые к системе. Например, это Gitlab, Jenkins, TeamCity.

Тем не менее предлагаю остановиться на GitLab.

- облачная система

    - GitLab имеет облачную версию сервиса, а также возможность развертывания собственного сервера.

- система контроля версий Git

    - GitLab использует Git как основную систему контроля версий.

- репозиторий на каждый сервис

    - В GitLab можно создавать отдельные репозитории для каждого сервиса.

- запуск сборки по событию из системы контроля версий

    - GitLab CI/CD позволяет автоматически запускать пайплайны на основе событий в репозитории, таких как push или merge request.

- запуск сборки по кнопке с указанием параметров

    - В GitLab CI/CD можно запускать пайплайны вручную, указывая параметры через интерфейс.

- возможность привязать настройки к каждой сборке

    - Использование конфигурационных файлов (.gitlab-ci.yml) позволяет привязывать настройки к каждой сборке.

- возможность создания шаблонов для различных конфигураций сборок

    - GitLab поддерживает создание шаблонов пайплайнов и их использование в различных проектах.

- возможность безопасного хранения секретных данных (пароли, ключи доступа)

    - GitLab предоставляет встроенное хранилище секретов (CI/CD Secrets) для безопасного хранения и использования секретных данных.

- несколько конфигураций для сборки из одного репозитория

    - В GitLab CI/CD можно определить несколько конфигураций сборки в одном репозитории, используя разные задачи и условия.

- кастомные шаги при сборке

    -  В GitLab CI/CD можно добавлять кастомные шаги в пайплайны.

- собственные докер-образы для сборки проектов

    - GitLab CI/CD поддерживает использование собственных Docker-образов для сборки проектов.

- возможность развернуть агентов сборки на собственных серверах

    - GitLab Runner можно развернуть на собственных серверах для выполнения сборок.

- возможность параллельного запуска нескольких сборок

    - GitLab CI/CD поддерживает параллельное выполнение нескольких сборок.

- возможность параллельного запуска тестов.

    - GitLab CI/CD позволяет параллельно запускать тесты, распределяя их по различным агентам сборки.


## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Решение 2

Предлагаю остановиться на ELK стеке.

Filebeat

- сбор логов в центральное хранилище со всех хостов, обслуживающих систему

    - Filebeat устанавливается на всех хостах, собирает логи и отправляет их в Logstash.

- минимальные требования к приложениям, сбор логов из stdout

    - Filebeat может собирать логи из stdout, что минимизирует требования к изменениям в приложениях.
- гарантированная доставка логов до центрального хранилища

    - Filebeat обеспечивает буферизацию и повторные попытки отправки логов в случае временной недоступности Logstash или Elasticsearch.

Logstash

- гарантированная доставка логов до центрального хранилища

    - Logstash получает логи от Filebeat, обрабатывает их и отправляет в Elasticsearch, обеспечивая надежную доставку.

- обеспечение поиска и фильтрации по записям логов

    - Logstash может обрабатывать и фильтровать логи перед отправкой в Elasticsearch, добавляя метаданные и выполняя другие преобразования.

Elasticsearch

- сбор логов в центральное хранилище со всех хостов, обслуживающих систему

    - Elasticsearch является центральным хранилищем, куда Logstash отправляет обработанные логи.

- обеспечение поиска и фильтрации по записям логов

    - Elasticsearch предоставляет мощные возможности для поиска и фильтрации логов, включая сложные запросы и агрегации.

Kibana

- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов

    - Kibana предоставляет пользовательский интерфейс для визуализации, анализа и поиска по логам.

- возможность дать ссылку на сохранённый поиск по записям логов

    - Kibana позволяет сохранять поисковые запросы и дашборды, предоставляя ссылки на них для совместного использования.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Решение 3

Предлагаю остановиться на  Prometheus + Grafana.

Компоненты:

-	Основной компонент — Prometheus. Prometheus получает метрики из разных сервисов и собирает их в одном месте.

-	Node exporter — небольшое приложение, собирающее метрики операционной системы и предоставляющее к ним доступ по HTTP. Prometheus собирает данные с одного или нескольких экземпляров Node Exporter.

-	Grafana — отображает данные из Prometheus в виде графиков и диаграмм, организованных в дашборды.


## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
